{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "230652bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Global.ipynb\n",
    "%run Helper_Functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abc1fb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATASET_DIR + \"/train_df.csv\", keep_default_na=False)\n",
    "train_df_ohe_full = pd.read_csv(DATASET_DIR + \"/train_df_ohe_full.csv\", keep_default_na=False)\n",
    "train_df_ohe_selected = pd.read_csv(DATASET_DIR + \"/train_df_ohe_selected.csv\", keep_default_na=False)\n",
    "train_df_oe = pd.read_csv(DATASET_DIR + \"/train_df_oe.csv\", keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29cbaa18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PublishYear</th>\n",
       "      <th>PublishMonth</th>\n",
       "      <th>PublishDay</th>\n",
       "      <th>pagesNumber</th>\n",
       "      <th>reading_writing</th>\n",
       "      <th>gay_lesbian</th>\n",
       "      <th>secret_life</th>\n",
       "      <th>travel_guide</th>\n",
       "      <th>seventeenth_century</th>\n",
       "      <th>best_practice</th>\n",
       "      <th>...</th>\n",
       "      <th>Publisher_zebra</th>\n",
       "      <th>Publisher_zebra books</th>\n",
       "      <th>Publisher_zed books</th>\n",
       "      <th>Publisher_zenith press</th>\n",
       "      <th>Publisher_zonderkidz</th>\n",
       "      <th>Publisher_zondervan</th>\n",
       "      <th>Publisher_zondervan academic</th>\n",
       "      <th>Publisher_zondervan publishing company</th>\n",
       "      <th>Publisher_zone books</th>\n",
       "      <th>Publisher_infrequent_sklearn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23058</th>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23059</th>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23060</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23061</th>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23062</th>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23063 rows × 4055 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PublishYear  PublishMonth  PublishDay  pagesNumber  reading_writing  \\\n",
       "0             13.0           3.0         0.0          0.0              0.0   \n",
       "1             12.0           5.0         0.0          0.0              0.0   \n",
       "2             13.0           1.0         6.0          0.0              0.0   \n",
       "3             13.0           4.0         0.0          0.0              0.0   \n",
       "4             13.0           3.0         1.0          0.0              0.0   \n",
       "...            ...           ...         ...          ...              ...   \n",
       "23058         12.0           3.0         0.0          0.0              0.0   \n",
       "23059         13.0           3.0         0.0          0.0              0.0   \n",
       "23060         12.0           1.0         3.0          0.0              0.0   \n",
       "23061         13.0           2.0         4.0          0.0              0.0   \n",
       "23062         13.0           3.0         2.0          0.0              0.0   \n",
       "\n",
       "       gay_lesbian  secret_life  travel_guide  seventeenth_century  \\\n",
       "0              0.0          0.0           0.0                  0.0   \n",
       "1              0.0          0.0           0.0                  0.0   \n",
       "2              0.0          0.0           0.0                  0.0   \n",
       "3              0.0          0.0           0.0                  0.0   \n",
       "4              0.0          0.0           0.0                  0.0   \n",
       "...            ...          ...           ...                  ...   \n",
       "23058          0.0          0.0           0.0                  0.0   \n",
       "23059          0.0          0.0           0.0                  0.0   \n",
       "23060          0.0          0.0           0.0                  0.0   \n",
       "23061          0.0          0.0           0.0                  0.0   \n",
       "23062          0.0          0.0           0.0                  0.0   \n",
       "\n",
       "       best_practice  ...  Publisher_zebra  Publisher_zebra books  \\\n",
       "0                0.0  ...              0.0                    0.0   \n",
       "1                0.0  ...              0.0                    0.0   \n",
       "2                0.0  ...              0.0                    0.0   \n",
       "3                0.0  ...              0.0                    0.0   \n",
       "4                0.0  ...              0.0                    0.0   \n",
       "...              ...  ...              ...                    ...   \n",
       "23058            0.0  ...              0.0                    0.0   \n",
       "23059            0.0  ...              0.0                    0.0   \n",
       "23060            0.0  ...              0.0                    0.0   \n",
       "23061            0.0  ...              0.0                    0.0   \n",
       "23062            0.0  ...              0.0                    0.0   \n",
       "\n",
       "       Publisher_zed books  Publisher_zenith press  Publisher_zonderkidz  \\\n",
       "0                      0.0                     0.0                   0.0   \n",
       "1                      0.0                     0.0                   0.0   \n",
       "2                      0.0                     0.0                   0.0   \n",
       "3                      0.0                     0.0                   0.0   \n",
       "4                      0.0                     0.0                   0.0   \n",
       "...                    ...                     ...                   ...   \n",
       "23058                  0.0                     0.0                   0.0   \n",
       "23059                  0.0                     0.0                   0.0   \n",
       "23060                  0.0                     0.0                   0.0   \n",
       "23061                  0.0                     0.0                   0.0   \n",
       "23062                  0.0                     0.0                   0.0   \n",
       "\n",
       "       Publisher_zondervan  Publisher_zondervan academic  \\\n",
       "0                      0.0                           0.0   \n",
       "1                      0.0                           0.0   \n",
       "2                      0.0                           0.0   \n",
       "3                      0.0                           0.0   \n",
       "4                      0.0                           0.0   \n",
       "...                    ...                           ...   \n",
       "23058                  0.0                           0.0   \n",
       "23059                  0.0                           0.0   \n",
       "23060                  0.0                           0.0   \n",
       "23061                  0.0                           0.0   \n",
       "23062                  0.0                           0.0   \n",
       "\n",
       "       Publisher_zondervan publishing company  Publisher_zone books  \\\n",
       "0                                         0.0                   0.0   \n",
       "1                                         0.0                   0.0   \n",
       "2                                         0.0                   0.0   \n",
       "3                                         0.0                   0.0   \n",
       "4                                         0.0                   0.0   \n",
       "...                                       ...                   ...   \n",
       "23058                                     0.0                   0.0   \n",
       "23059                                     0.0                   0.0   \n",
       "23060                                     0.0                   0.0   \n",
       "23061                                     0.0                   0.0   \n",
       "23062                                     0.0                   0.0   \n",
       "\n",
       "       Publisher_infrequent_sklearn  \n",
       "0                               0.0  \n",
       "1                               0.0  \n",
       "2                               0.0  \n",
       "3                               0.0  \n",
       "4                               0.0  \n",
       "...                             ...  \n",
       "23058                           0.0  \n",
       "23059                           0.0  \n",
       "23060                           0.0  \n",
       "23061                           1.0  \n",
       "23062                           0.0  \n",
       "\n",
       "[23063 rows x 4055 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train_df.iloc[:,-1]\n",
    "\n",
    "X = train_df.iloc[:,:-1]\n",
    "X_ohe_full = train_df_ohe_full.iloc[:,:-1]\n",
    "X_ohe_selected = train_df_ohe_selected.iloc[:,:-1]\n",
    "X_oe = train_df_oe.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1588dd1c",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1913eb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8529b1",
   "metadata": {},
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7521dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "[CV] END ................................................C=1; total time=   6.1s\n",
      "[CV] END ................................................C=1; total time=   6.1s\n",
      "[CV] END ................................................C=1; total time=   6.2s\n",
      "[CV] END ................................................C=1; total time=   6.2s\n",
      "[CV] END ................................................C=1; total time=   6.6s\n",
      "[CV] END ...............................................C=11; total time=   6.5s\n",
      "[CV] END ...............................................C=11; total time=   6.4s\n",
      "[CV] END ...............................................C=11; total time=   6.4s\n",
      "[CV] END ...............................................C=11; total time=   6.4s\n",
      "[CV] END ...............................................C=11; total time=   6.4s\n",
      "[CV] END ...............................................C=21; total time=   6.4s\n",
      "[CV] END ...............................................C=21; total time=   6.4s\n",
      "[CV] END ...............................................C=21; total time=   6.3s\n",
      "[CV] END ...............................................C=21; total time=   6.4s\n",
      "[CV] END ...............................................C=21; total time=   6.4s\n",
      "[CV] END ...............................................C=31; total time=   6.4s\n",
      "[CV] END ...............................................C=31; total time=   6.4s\n",
      "[CV] END ...............................................C=31; total time=   6.4s\n",
      "[CV] END ...............................................C=31; total time=   6.3s\n",
      "[CV] END ...............................................C=31; total time=   6.3s\n",
      "[CV] END ...............................................C=41; total time=   6.3s\n",
      "[CV] END ...............................................C=41; total time=   6.4s\n",
      "[CV] END ...............................................C=41; total time=   6.4s\n",
      "[CV] END ...............................................C=41; total time=   6.4s\n",
      "[CV] END ...............................................C=41; total time=   6.3s\n",
      "[CV] END ...............................................C=51; total time=   6.4s\n",
      "[CV] END ...............................................C=51; total time=   6.5s\n",
      "[CV] END ...............................................C=51; total time=   6.4s\n",
      "[CV] END ...............................................C=51; total time=   6.4s\n",
      "[CV] END ...............................................C=51; total time=   6.4s\n",
      "[CV] END ...............................................C=61; total time=   6.4s\n",
      "[CV] END ...............................................C=61; total time=   6.3s\n",
      "[CV] END ...............................................C=61; total time=   6.4s\n",
      "[CV] END ...............................................C=61; total time=   6.4s\n",
      "[CV] END ...............................................C=61; total time=   6.4s\n",
      "[CV] END ...............................................C=71; total time=   6.4s\n",
      "[CV] END ...............................................C=71; total time=   6.6s\n",
      "[CV] END ...............................................C=71; total time=   6.5s\n",
      "[CV] END ...............................................C=71; total time=   6.5s\n",
      "[CV] END ...............................................C=71; total time=   6.5s\n",
      "[CV] END ...............................................C=81; total time=   6.4s\n",
      "[CV] END ...............................................C=81; total time=   6.5s\n",
      "[CV] END ...............................................C=81; total time=   6.4s\n",
      "[CV] END ...............................................C=81; total time=   6.5s\n",
      "[CV] END ...............................................C=81; total time=   6.4s\n",
      "[CV] END ...............................................C=91; total time=   6.4s\n",
      "[CV] END ...............................................C=91; total time=   6.5s\n",
      "[CV] END ...............................................C=91; total time=   6.4s\n",
      "[CV] END ...............................................C=91; total time=   6.4s\n",
      "[CV] END ...............................................C=91; total time=   6.4s\n",
      "[CV] END ..............................................C=101; total time=   6.4s\n",
      "[CV] END ..............................................C=101; total time=   6.4s\n",
      "[CV] END ..............................................C=101; total time=   6.4s\n",
      "[CV] END ..............................................C=101; total time=   6.4s\n",
      "[CV] END ..............................................C=101; total time=   6.5s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_3.0_precision</th>\n",
       "      <th>std_test_3.0_precision</th>\n",
       "      <th>rank_test_3.0_precision</th>\n",
       "      <th>mean_test_3.0_recall</th>\n",
       "      <th>std_test_3.0_recall</th>\n",
       "      <th>rank_test_3.0_recall</th>\n",
       "      <th>mean_test_3.0_f1-score</th>\n",
       "      <th>std_test_3.0_f1-score</th>\n",
       "      <th>rank_test_3.0_f1-score</th>\n",
       "      <th>...</th>\n",
       "      <th>rank_test_5.0_precision</th>\n",
       "      <th>mean_test_5.0_recall</th>\n",
       "      <th>std_test_5.0_recall</th>\n",
       "      <th>rank_test_5.0_recall</th>\n",
       "      <th>mean_test_5.0_f1-score</th>\n",
       "      <th>std_test_5.0_f1-score</th>\n",
       "      <th>rank_test_5.0_f1-score</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.515153</td>\n",
       "      <td>0.013062</td>\n",
       "      <td>3</td>\n",
       "      <td>0.290587</td>\n",
       "      <td>0.011042</td>\n",
       "      <td>9</td>\n",
       "      <td>0.371235</td>\n",
       "      <td>0.005780</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.198787</td>\n",
       "      <td>0.027009</td>\n",
       "      <td>10</td>\n",
       "      <td>0.286705</td>\n",
       "      <td>0.031279</td>\n",
       "      <td>3</td>\n",
       "      <td>0.709925</td>\n",
       "      <td>0.003349</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'C': 11}</td>\n",
       "      <td>0.424720</td>\n",
       "      <td>0.069845</td>\n",
       "      <td>11</td>\n",
       "      <td>0.504137</td>\n",
       "      <td>0.177955</td>\n",
       "      <td>2</td>\n",
       "      <td>0.430337</td>\n",
       "      <td>0.045645</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.208746</td>\n",
       "      <td>0.071250</td>\n",
       "      <td>8</td>\n",
       "      <td>0.279508</td>\n",
       "      <td>0.042311</td>\n",
       "      <td>5</td>\n",
       "      <td>0.640683</td>\n",
       "      <td>0.064105</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'C': 21}</td>\n",
       "      <td>0.459453</td>\n",
       "      <td>0.170122</td>\n",
       "      <td>6</td>\n",
       "      <td>0.514418</td>\n",
       "      <td>0.343618</td>\n",
       "      <td>1</td>\n",
       "      <td>0.342042</td>\n",
       "      <td>0.147387</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.202741</td>\n",
       "      <td>0.050568</td>\n",
       "      <td>9</td>\n",
       "      <td>0.259685</td>\n",
       "      <td>0.034593</td>\n",
       "      <td>8</td>\n",
       "      <td>0.584230</td>\n",
       "      <td>0.102320</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'C': 31}</td>\n",
       "      <td>0.428744</td>\n",
       "      <td>0.073634</td>\n",
       "      <td>10</td>\n",
       "      <td>0.473524</td>\n",
       "      <td>0.174780</td>\n",
       "      <td>6</td>\n",
       "      <td>0.416323</td>\n",
       "      <td>0.056948</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.224978</td>\n",
       "      <td>0.043922</td>\n",
       "      <td>5</td>\n",
       "      <td>0.288968</td>\n",
       "      <td>0.028692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.643367</td>\n",
       "      <td>0.052604</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'C': 41}</td>\n",
       "      <td>0.451168</td>\n",
       "      <td>0.130420</td>\n",
       "      <td>7</td>\n",
       "      <td>0.487882</td>\n",
       "      <td>0.296944</td>\n",
       "      <td>4</td>\n",
       "      <td>0.375210</td>\n",
       "      <td>0.093843</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.263286</td>\n",
       "      <td>0.079254</td>\n",
       "      <td>2</td>\n",
       "      <td>0.285626</td>\n",
       "      <td>0.028679</td>\n",
       "      <td>4</td>\n",
       "      <td>0.601306</td>\n",
       "      <td>0.119337</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'C': 51}</td>\n",
       "      <td>0.563270</td>\n",
       "      <td>0.091559</td>\n",
       "      <td>2</td>\n",
       "      <td>0.218790</td>\n",
       "      <td>0.129003</td>\n",
       "      <td>10</td>\n",
       "      <td>0.280614</td>\n",
       "      <td>0.112187</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.280605</td>\n",
       "      <td>0.175093</td>\n",
       "      <td>1</td>\n",
       "      <td>0.236989</td>\n",
       "      <td>0.062332</td>\n",
       "      <td>11</td>\n",
       "      <td>0.656370</td>\n",
       "      <td>0.092066</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'C': 61}</td>\n",
       "      <td>0.440812</td>\n",
       "      <td>0.131251</td>\n",
       "      <td>9</td>\n",
       "      <td>0.488523</td>\n",
       "      <td>0.349434</td>\n",
       "      <td>3</td>\n",
       "      <td>0.346863</td>\n",
       "      <td>0.094164</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.190731</td>\n",
       "      <td>0.048116</td>\n",
       "      <td>11</td>\n",
       "      <td>0.251105</td>\n",
       "      <td>0.028590</td>\n",
       "      <td>10</td>\n",
       "      <td>0.576679</td>\n",
       "      <td>0.161813</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'C': 71}</td>\n",
       "      <td>0.508983</td>\n",
       "      <td>0.115902</td>\n",
       "      <td>4</td>\n",
       "      <td>0.345660</td>\n",
       "      <td>0.251118</td>\n",
       "      <td>8</td>\n",
       "      <td>0.336618</td>\n",
       "      <td>0.088267</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.211903</td>\n",
       "      <td>0.024907</td>\n",
       "      <td>7</td>\n",
       "      <td>0.287674</td>\n",
       "      <td>0.024650</td>\n",
       "      <td>2</td>\n",
       "      <td>0.664141</td>\n",
       "      <td>0.090619</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'C': 81}</td>\n",
       "      <td>0.446389</td>\n",
       "      <td>0.117618</td>\n",
       "      <td>8</td>\n",
       "      <td>0.483919</td>\n",
       "      <td>0.265771</td>\n",
       "      <td>5</td>\n",
       "      <td>0.380462</td>\n",
       "      <td>0.107247</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.232110</td>\n",
       "      <td>0.069533</td>\n",
       "      <td>3</td>\n",
       "      <td>0.276126</td>\n",
       "      <td>0.030432</td>\n",
       "      <td>6</td>\n",
       "      <td>0.618778</td>\n",
       "      <td>0.080068</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'C': 91}</td>\n",
       "      <td>0.576891</td>\n",
       "      <td>0.024017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.161154</td>\n",
       "      <td>0.033152</td>\n",
       "      <td>11</td>\n",
       "      <td>0.249433</td>\n",
       "      <td>0.041809</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.216964</td>\n",
       "      <td>0.048803</td>\n",
       "      <td>6</td>\n",
       "      <td>0.275235</td>\n",
       "      <td>0.026660</td>\n",
       "      <td>7</td>\n",
       "      <td>0.710922</td>\n",
       "      <td>0.007157</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'C': 101}</td>\n",
       "      <td>0.463027</td>\n",
       "      <td>0.081625</td>\n",
       "      <td>5</td>\n",
       "      <td>0.389555</td>\n",
       "      <td>0.206704</td>\n",
       "      <td>7</td>\n",
       "      <td>0.373296</td>\n",
       "      <td>0.086883</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.231105</td>\n",
       "      <td>0.081211</td>\n",
       "      <td>4</td>\n",
       "      <td>0.258993</td>\n",
       "      <td>0.035218</td>\n",
       "      <td>9</td>\n",
       "      <td>0.655164</td>\n",
       "      <td>0.059994</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        params  mean_test_3.0_precision  std_test_3.0_precision  \\\n",
       "0     {'C': 1}                 0.515153                0.013062   \n",
       "1    {'C': 11}                 0.424720                0.069845   \n",
       "2    {'C': 21}                 0.459453                0.170122   \n",
       "3    {'C': 31}                 0.428744                0.073634   \n",
       "4    {'C': 41}                 0.451168                0.130420   \n",
       "5    {'C': 51}                 0.563270                0.091559   \n",
       "6    {'C': 61}                 0.440812                0.131251   \n",
       "7    {'C': 71}                 0.508983                0.115902   \n",
       "8    {'C': 81}                 0.446389                0.117618   \n",
       "9    {'C': 91}                 0.576891                0.024017   \n",
       "10  {'C': 101}                 0.463027                0.081625   \n",
       "\n",
       "    rank_test_3.0_precision  mean_test_3.0_recall  std_test_3.0_recall  \\\n",
       "0                         3              0.290587             0.011042   \n",
       "1                        11              0.504137             0.177955   \n",
       "2                         6              0.514418             0.343618   \n",
       "3                        10              0.473524             0.174780   \n",
       "4                         7              0.487882             0.296944   \n",
       "5                         2              0.218790             0.129003   \n",
       "6                         9              0.488523             0.349434   \n",
       "7                         4              0.345660             0.251118   \n",
       "8                         8              0.483919             0.265771   \n",
       "9                         1              0.161154             0.033152   \n",
       "10                        5              0.389555             0.206704   \n",
       "\n",
       "    rank_test_3.0_recall  mean_test_3.0_f1-score  std_test_3.0_f1-score  \\\n",
       "0                      9                0.371235               0.005780   \n",
       "1                      2                0.430337               0.045645   \n",
       "2                      1                0.342042               0.147387   \n",
       "3                      6                0.416323               0.056948   \n",
       "4                      4                0.375210               0.093843   \n",
       "5                     10                0.280614               0.112187   \n",
       "6                      3                0.346863               0.094164   \n",
       "7                      8                0.336618               0.088267   \n",
       "8                      5                0.380462               0.107247   \n",
       "9                     11                0.249433               0.041809   \n",
       "10                     7                0.373296               0.086883   \n",
       "\n",
       "    rank_test_3.0_f1-score  ...  rank_test_5.0_precision  \\\n",
       "0                        6  ...                        1   \n",
       "1                        1  ...                        2   \n",
       "2                        8  ...                        4   \n",
       "3                        2  ...                        6   \n",
       "4                        4  ...                       11   \n",
       "5                       10  ...                       10   \n",
       "6                        7  ...                        3   \n",
       "7                        9  ...                        5   \n",
       "8                        3  ...                        8   \n",
       "9                       11  ...                        7   \n",
       "10                       5  ...                        9   \n",
       "\n",
       "    mean_test_5.0_recall  std_test_5.0_recall  rank_test_5.0_recall  \\\n",
       "0               0.198787             0.027009                    10   \n",
       "1               0.208746             0.071250                     8   \n",
       "2               0.202741             0.050568                     9   \n",
       "3               0.224978             0.043922                     5   \n",
       "4               0.263286             0.079254                     2   \n",
       "5               0.280605             0.175093                     1   \n",
       "6               0.190731             0.048116                    11   \n",
       "7               0.211903             0.024907                     7   \n",
       "8               0.232110             0.069533                     3   \n",
       "9               0.216964             0.048803                     6   \n",
       "10              0.231105             0.081211                     4   \n",
       "\n",
       "    mean_test_5.0_f1-score  std_test_5.0_f1-score  rank_test_5.0_f1-score  \\\n",
       "0                 0.286705               0.031279                       3   \n",
       "1                 0.279508               0.042311                       5   \n",
       "2                 0.259685               0.034593                       8   \n",
       "3                 0.288968               0.028692                       1   \n",
       "4                 0.285626               0.028679                       4   \n",
       "5                 0.236989               0.062332                      11   \n",
       "6                 0.251105               0.028590                      10   \n",
       "7                 0.287674               0.024650                       2   \n",
       "8                 0.276126               0.030432                       6   \n",
       "9                 0.275235               0.026660                       7   \n",
       "10                0.258993               0.035218                       9   \n",
       "\n",
       "    mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "0             0.709925           0.003349                   2  \n",
       "1             0.640683           0.064105                   7  \n",
       "2             0.584230           0.102320                  10  \n",
       "3             0.643367           0.052604                   6  \n",
       "4             0.601306           0.119337                   9  \n",
       "5             0.656370           0.092066                   4  \n",
       "6             0.576679           0.161813                  11  \n",
       "7             0.664141           0.090619                   3  \n",
       "8             0.618778           0.080068                   8  \n",
       "9             0.710922           0.007157                   1  \n",
       "10            0.655164           0.059994                   5  \n",
       "\n",
       "[11 rows x 31 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First try with Linear SVM\n",
    "linearSVM = svm.LinearSVC(random_state=30027)\n",
    "param_grid = {'C': range(1,102,10)}\n",
    "tune_hyperparameter(linearSVM, param_grid, X_ohe_full, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ad0b167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] END ...............................................C=85; total time=   5.6s\n",
      "[CV] END ...............................................C=85; total time=   5.5s\n",
      "[CV] END ...............................................C=85; total time=   5.4s\n",
      "[CV] END ...............................................C=86; total time=   5.5s\n",
      "[CV] END ...............................................C=86; total time=   5.4s\n",
      "[CV] END ...............................................C=86; total time=   5.4s\n",
      "[CV] END ...............................................C=87; total time=   5.6s\n",
      "[CV] END ...............................................C=87; total time=   5.4s\n",
      "[CV] END ...............................................C=87; total time=   5.6s\n",
      "[CV] END ...............................................C=88; total time=   5.6s\n",
      "[CV] END ...............................................C=88; total time=   5.6s\n",
      "[CV] END ...............................................C=88; total time=   5.4s\n",
      "[CV] END ...............................................C=89; total time=   5.5s\n",
      "[CV] END ...............................................C=89; total time=   5.5s\n",
      "[CV] END ...............................................C=89; total time=   5.5s\n",
      "[CV] END ...............................................C=90; total time=   5.4s\n",
      "[CV] END ...............................................C=90; total time=   5.5s\n",
      "[CV] END ...............................................C=90; total time=   5.4s\n",
      "[CV] END ...............................................C=91; total time=   5.4s\n",
      "[CV] END ...............................................C=91; total time=   5.4s\n",
      "[CV] END ...............................................C=91; total time=   5.4s\n",
      "[CV] END ...............................................C=92; total time=   5.5s\n",
      "[CV] END ...............................................C=92; total time=   5.4s\n",
      "[CV] END ...............................................C=92; total time=   5.5s\n",
      "[CV] END ...............................................C=93; total time=   5.5s\n",
      "[CV] END ...............................................C=93; total time=   5.5s\n",
      "[CV] END ...............................................C=93; total time=   5.5s\n",
      "[CV] END ...............................................C=94; total time=   5.6s\n",
      "[CV] END ...............................................C=94; total time=   5.5s\n",
      "[CV] END ...............................................C=94; total time=   5.4s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_3.0_precision</th>\n",
       "      <th>std_test_3.0_precision</th>\n",
       "      <th>rank_test_3.0_precision</th>\n",
       "      <th>mean_test_3.0_recall</th>\n",
       "      <th>std_test_3.0_recall</th>\n",
       "      <th>rank_test_3.0_recall</th>\n",
       "      <th>mean_test_3.0_f1-score</th>\n",
       "      <th>std_test_3.0_f1-score</th>\n",
       "      <th>rank_test_3.0_f1-score</th>\n",
       "      <th>...</th>\n",
       "      <th>rank_test_5.0_precision</th>\n",
       "      <th>mean_test_5.0_recall</th>\n",
       "      <th>std_test_5.0_recall</th>\n",
       "      <th>rank_test_5.0_recall</th>\n",
       "      <th>mean_test_5.0_f1-score</th>\n",
       "      <th>std_test_5.0_f1-score</th>\n",
       "      <th>rank_test_5.0_f1-score</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'C': 85}</td>\n",
       "      <td>0.414334</td>\n",
       "      <td>0.050811</td>\n",
       "      <td>9</td>\n",
       "      <td>0.468600</td>\n",
       "      <td>0.172974</td>\n",
       "      <td>2</td>\n",
       "      <td>0.415250</td>\n",
       "      <td>0.033919</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.328075</td>\n",
       "      <td>0.087429</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243546</td>\n",
       "      <td>0.042527</td>\n",
       "      <td>8</td>\n",
       "      <td>0.603955</td>\n",
       "      <td>0.069105</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'C': 86}</td>\n",
       "      <td>0.472643</td>\n",
       "      <td>0.092225</td>\n",
       "      <td>5</td>\n",
       "      <td>0.347346</td>\n",
       "      <td>0.245798</td>\n",
       "      <td>4</td>\n",
       "      <td>0.327750</td>\n",
       "      <td>0.093450</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.235183</td>\n",
       "      <td>0.080479</td>\n",
       "      <td>5</td>\n",
       "      <td>0.269321</td>\n",
       "      <td>0.010059</td>\n",
       "      <td>4</td>\n",
       "      <td>0.650655</td>\n",
       "      <td>0.084640</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'C': 87}</td>\n",
       "      <td>0.464826</td>\n",
       "      <td>0.073156</td>\n",
       "      <td>7</td>\n",
       "      <td>0.316658</td>\n",
       "      <td>0.173248</td>\n",
       "      <td>7</td>\n",
       "      <td>0.334813</td>\n",
       "      <td>0.074519</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.209909</td>\n",
       "      <td>0.071861</td>\n",
       "      <td>8</td>\n",
       "      <td>0.261365</td>\n",
       "      <td>0.032843</td>\n",
       "      <td>7</td>\n",
       "      <td>0.668600</td>\n",
       "      <td>0.056188</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'C': 88}</td>\n",
       "      <td>0.492649</td>\n",
       "      <td>0.042187</td>\n",
       "      <td>3</td>\n",
       "      <td>0.239759</td>\n",
       "      <td>0.071727</td>\n",
       "      <td>8</td>\n",
       "      <td>0.312340</td>\n",
       "      <td>0.049164</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.198785</td>\n",
       "      <td>0.017509</td>\n",
       "      <td>9</td>\n",
       "      <td>0.278690</td>\n",
       "      <td>0.012652</td>\n",
       "      <td>1</td>\n",
       "      <td>0.699041</td>\n",
       "      <td>0.013469</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'C': 89}</td>\n",
       "      <td>0.445579</td>\n",
       "      <td>0.103760</td>\n",
       "      <td>8</td>\n",
       "      <td>0.438340</td>\n",
       "      <td>0.300367</td>\n",
       "      <td>3</td>\n",
       "      <td>0.357778</td>\n",
       "      <td>0.061797</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.188639</td>\n",
       "      <td>0.047944</td>\n",
       "      <td>10</td>\n",
       "      <td>0.264292</td>\n",
       "      <td>0.038761</td>\n",
       "      <td>5</td>\n",
       "      <td>0.616576</td>\n",
       "      <td>0.132009</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'C': 90}</td>\n",
       "      <td>0.350190</td>\n",
       "      <td>0.039104</td>\n",
       "      <td>10</td>\n",
       "      <td>0.670561</td>\n",
       "      <td>0.167592</td>\n",
       "      <td>1</td>\n",
       "      <td>0.445465</td>\n",
       "      <td>0.018410</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.306689</td>\n",
       "      <td>0.092691</td>\n",
       "      <td>2</td>\n",
       "      <td>0.274539</td>\n",
       "      <td>0.007351</td>\n",
       "      <td>3</td>\n",
       "      <td>0.532547</td>\n",
       "      <td>0.096568</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'C': 91}</td>\n",
       "      <td>0.470543</td>\n",
       "      <td>0.090178</td>\n",
       "      <td>6</td>\n",
       "      <td>0.335922</td>\n",
       "      <td>0.243775</td>\n",
       "      <td>5</td>\n",
       "      <td>0.318738</td>\n",
       "      <td>0.099157</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.267430</td>\n",
       "      <td>0.141943</td>\n",
       "      <td>3</td>\n",
       "      <td>0.220360</td>\n",
       "      <td>0.054370</td>\n",
       "      <td>9</td>\n",
       "      <td>0.624846</td>\n",
       "      <td>0.117154</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'C': 92}</td>\n",
       "      <td>0.483794</td>\n",
       "      <td>0.104373</td>\n",
       "      <td>4</td>\n",
       "      <td>0.326195</td>\n",
       "      <td>0.267434</td>\n",
       "      <td>6</td>\n",
       "      <td>0.298641</td>\n",
       "      <td>0.111457</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.239205</td>\n",
       "      <td>0.127853</td>\n",
       "      <td>4</td>\n",
       "      <td>0.220071</td>\n",
       "      <td>0.031661</td>\n",
       "      <td>10</td>\n",
       "      <td>0.631437</td>\n",
       "      <td>0.113040</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'C': 93}</td>\n",
       "      <td>0.546340</td>\n",
       "      <td>0.024294</td>\n",
       "      <td>1</td>\n",
       "      <td>0.190133</td>\n",
       "      <td>0.061960</td>\n",
       "      <td>10</td>\n",
       "      <td>0.275042</td>\n",
       "      <td>0.062069</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.221993</td>\n",
       "      <td>0.040954</td>\n",
       "      <td>6</td>\n",
       "      <td>0.276839</td>\n",
       "      <td>0.022161</td>\n",
       "      <td>2</td>\n",
       "      <td>0.707020</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'C': 94}</td>\n",
       "      <td>0.522116</td>\n",
       "      <td>0.017162</td>\n",
       "      <td>2</td>\n",
       "      <td>0.217086</td>\n",
       "      <td>0.046876</td>\n",
       "      <td>9</td>\n",
       "      <td>0.303242</td>\n",
       "      <td>0.045051</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.210858</td>\n",
       "      <td>0.044674</td>\n",
       "      <td>7</td>\n",
       "      <td>0.264120</td>\n",
       "      <td>0.030343</td>\n",
       "      <td>6</td>\n",
       "      <td>0.703898</td>\n",
       "      <td>0.008722</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      params  mean_test_3.0_precision  std_test_3.0_precision  \\\n",
       "0  {'C': 85}                 0.414334                0.050811   \n",
       "1  {'C': 86}                 0.472643                0.092225   \n",
       "2  {'C': 87}                 0.464826                0.073156   \n",
       "3  {'C': 88}                 0.492649                0.042187   \n",
       "4  {'C': 89}                 0.445579                0.103760   \n",
       "5  {'C': 90}                 0.350190                0.039104   \n",
       "6  {'C': 91}                 0.470543                0.090178   \n",
       "7  {'C': 92}                 0.483794                0.104373   \n",
       "8  {'C': 93}                 0.546340                0.024294   \n",
       "9  {'C': 94}                 0.522116                0.017162   \n",
       "\n",
       "   rank_test_3.0_precision  mean_test_3.0_recall  std_test_3.0_recall  \\\n",
       "0                        9              0.468600             0.172974   \n",
       "1                        5              0.347346             0.245798   \n",
       "2                        7              0.316658             0.173248   \n",
       "3                        3              0.239759             0.071727   \n",
       "4                        8              0.438340             0.300367   \n",
       "5                       10              0.670561             0.167592   \n",
       "6                        6              0.335922             0.243775   \n",
       "7                        4              0.326195             0.267434   \n",
       "8                        1              0.190133             0.061960   \n",
       "9                        2              0.217086             0.046876   \n",
       "\n",
       "   rank_test_3.0_recall  mean_test_3.0_f1-score  std_test_3.0_f1-score  \\\n",
       "0                     2                0.415250               0.033919   \n",
       "1                     4                0.327750               0.093450   \n",
       "2                     7                0.334813               0.074519   \n",
       "3                     8                0.312340               0.049164   \n",
       "4                     3                0.357778               0.061797   \n",
       "5                     1                0.445465               0.018410   \n",
       "6                     5                0.318738               0.099157   \n",
       "7                     6                0.298641               0.111457   \n",
       "8                    10                0.275042               0.062069   \n",
       "9                     9                0.303242               0.045051   \n",
       "\n",
       "   rank_test_3.0_f1-score  ...  rank_test_5.0_precision  mean_test_5.0_recall  \\\n",
       "0                       2  ...                       10              0.328075   \n",
       "1                       5  ...                        4              0.235183   \n",
       "2                       4  ...                        3              0.209909   \n",
       "3                       7  ...                        2              0.198785   \n",
       "4                       3  ...                        1              0.188639   \n",
       "5                       1  ...                        9              0.306689   \n",
       "6                       6  ...                        8              0.267430   \n",
       "7                       9  ...                        7              0.239205   \n",
       "8                      10  ...                        6              0.221993   \n",
       "9                       8  ...                        5              0.210858   \n",
       "\n",
       "   std_test_5.0_recall  rank_test_5.0_recall  mean_test_5.0_f1-score  \\\n",
       "0             0.087429                     1                0.243546   \n",
       "1             0.080479                     5                0.269321   \n",
       "2             0.071861                     8                0.261365   \n",
       "3             0.017509                     9                0.278690   \n",
       "4             0.047944                    10                0.264292   \n",
       "5             0.092691                     2                0.274539   \n",
       "6             0.141943                     3                0.220360   \n",
       "7             0.127853                     4                0.220071   \n",
       "8             0.040954                     6                0.276839   \n",
       "9             0.044674                     7                0.264120   \n",
       "\n",
       "   std_test_5.0_f1-score  rank_test_5.0_f1-score  mean_test_accuracy  \\\n",
       "0               0.042527                       8            0.603955   \n",
       "1               0.010059                       4            0.650655   \n",
       "2               0.032843                       7            0.668600   \n",
       "3               0.012652                       1            0.699041   \n",
       "4               0.038761                       5            0.616576   \n",
       "5               0.007351                       3            0.532547   \n",
       "6               0.054370                       9            0.624846   \n",
       "7               0.031661                      10            0.631437   \n",
       "8               0.022161                       2            0.707020   \n",
       "9               0.030343                       6            0.703898   \n",
       "\n",
       "   std_test_accuracy  rank_test_accuracy  \n",
       "0           0.069105                   9  \n",
       "1           0.084640                   5  \n",
       "2           0.056188                   4  \n",
       "3           0.013469                   3  \n",
       "4           0.132009                   8  \n",
       "5           0.096568                  10  \n",
       "6           0.117154                   7  \n",
       "7           0.113040                   6  \n",
       "8           0.003186                   1  \n",
       "9           0.008722                   2  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Narrow down\n",
    "linearSVM = svm.LinearSVC(random_state=30027)\n",
    "param_grid = {'C': range(85, 95)}\n",
    "tune_hyperparameter(linearSVM, param_grid, X_ohe_full, y, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ee008e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         3.0       0.36      0.34      0.35      5864\n",
      "         4.0       0.74      0.76      0.75     16208\n",
      "         5.0       0.29      0.22      0.25       991\n",
      "\n",
      "    accuracy                           0.63     23063\n",
      "   macro avg       0.46      0.44      0.45     23063\n",
      "weighted avg       0.63      0.63      0.63     23063\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4., 4., 4., ..., 4., 4., 4.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearSVM = svm.LinearSVC(random_state=30027, C=93)\n",
    "linearSVM.fit(X_ohe_selected, y_train)\n",
    "cv_evaluate(linearSVM, X_ohe_selected, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4797a1",
   "metadata": {},
   "source": [
    "### Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2d1328b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# tune hyperparameter C and gamma\u001b[39;00m\n\u001b[1;32m      5\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m101\u001b[39m, \u001b[38;5;241m25\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.7\u001b[39m, \u001b[38;5;241m0.9\u001b[39m]}\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtune_hyperparameter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRBF_svm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_ohe_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/var/folders/tk/2zq7clf94gx3rdh5slf6rhc00000gn/T/ipykernel_12524/2586731994.py:4\u001b[0m, in \u001b[0;36mtune_hyperparameter\u001b[0;34m(clf, param_grid, X, y, scoring, cv)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtune_hyperparameter\u001b[39m(clf, param_grid, X, y, scoring\u001b[38;5;241m=\u001b[39mreport_scoring, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m): \n\u001b[1;32m      2\u001b[0m     grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(clf, param_grid, scoring\u001b[38;5;241m=\u001b[39mscoring, cv\u001b[38;5;241m=\u001b[39mcv, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, error_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     result_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(grid_search\u001b[38;5;241m.\u001b[39mcv_results_)\n\u001b[1;32m      6\u001b[0m     r \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^((mean|std|rank)_test|params).*\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:708\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    705\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    707\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m--> 708\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m \u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m score_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m-\u001b[39m fit_time\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:767\u001b[0m, in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[1;32m    765\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test)\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 767\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;66;03m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[1;32m    771\u001b[0m         \u001b[38;5;66;03m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/tk/2zq7clf94gx3rdh5slf6rhc00000gn/T/ipykernel_12524/3619825082.py:3\u001b[0m, in \u001b[0;36mreport_scoring\u001b[0;34m(clf, X, y, include_avg)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreport_scoring\u001b[39m(clf, X, y, include_avg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m): \n\u001b[0;32m----> 3\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     results \u001b[38;5;241m=\u001b[39m classification_report(y, y_pred, output_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m     report_dict \u001b[38;5;241m=\u001b[39m {}  \u001b[38;5;66;03m# set up our own output dictionary\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:820\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    818\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp))\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:435\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    433\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_for_predict(X)\n\u001b[1;32m    434\u001b[0m predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[0;32m--> 435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:454\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX.shape[1] = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be equal to \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe number of samples at training time\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m             \u001b[38;5;241m%\u001b[39m (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    450\u001b[0m         )\n\u001b[1;32m    452\u001b[0m svm_type \u001b[38;5;241m=\u001b[39m LIBSVM_IMPL\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlibsvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_vectors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_support\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dual_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_intercept_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_probA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_probB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msvm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Try with Kernel SVM\n",
    "RBF_svm = svm.SVC(kernel='rbf')\n",
    "\n",
    "# tune hyperparameter C and gamma\n",
    "param_grid = {'C': range(1, 101, 25), 'gamma': [0.1, 0.3, 0.5, 0.7, 0.9]}\n",
    "tune_hyperparameter(RBF_svm, param_grid, X_ohe_full, y, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e3c363",
   "metadata": {},
   "outputs": [],
   "source": [
    "RBF_svm = svm.SVC(kernel='rbf', gamma=0.3, C=1)\n",
    "RBF_svm.fit(X_ohe_full, y_train)\n",
    "cv_evaluate(RBF_svm, X_ohe_full, y)\n",
    "# Kernel SVM performs slightly better on weighted avg precision & recall than Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f34d75",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532498ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logr = LogisticRegression(solver='sag') # uses Stochastic Average Gradient descent solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f098f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_iter': [100, 500, 1000, 5000, 10000]}\n",
    "cv_results = tune_hyperparameter(logr, param_grid, X_ohe_selected, y, cv=3)\n",
    "cv_results\n",
    "# max_iter>=500 works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038b4dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "logr = LogisticRegression(solver='sag', max_iter=100)\n",
    "logr.fit(X_ohe_selected, y)\n",
    "cv_evaluate(logr, X_ohe_selected, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc7dec0",
   "metadata": {},
   "source": [
    "# Boosting with Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d158e090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(random_state=30027)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb240a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning using GridSearch\n",
    "param_grid = {\n",
    "    'learning_rate': (0.01, 0.1, 1, 10),\n",
    "    'max_leaf_nodes': (3, 10, 30)}\n",
    "cv_results = tune_hyperparameter(hgb, param_grid, X_oe, y, cv=5)\n",
    "cv_results\n",
    "# 'Best' param set: learning_rate = 0.1, max_leaf_nodes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1d01e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd go\n",
    "hgb = HistGradientBoostingClassifier(random_state=30027, learning_rate=0.1)\n",
    "param_grid = {\n",
    "    'max_leaf_nodes': range(10, 30, 2)}\n",
    "cv_results = tune_hyperparameter(hgb, param_grid, X_oe, y, cv=5)\n",
    "cv_results\n",
    "# 'Best' param set: learning_rate = 0.01, max_leaf_nodes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fdbc7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hgb = HistGradientBoostingClassifier(random_state=30027, max_leaf_nodes=22, learning_rate=0.1)\n",
    "hgb.fit(X_oe, y)\n",
    "cv_evaluate(hgb, X_oe, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c0706b",
   "metadata": {},
   "source": [
    "# Baseline - 0R & 1R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669a2fe5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-16T08:33:57.307355Z",
     "iopub.status.busy": "2023-04-16T08:33:57.306901Z",
     "iopub.status.idle": "2023-04-16T08:33:57.359791Z",
     "shell.execute_reply": "2023-04-16T08:33:57.358692Z",
     "shell.execute_reply.started": "2023-04-16T08:33:57.307317Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7202ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0R\n",
    "zero_r = DummyClassifier(strategy='most_frequent')\n",
    "cross_val(zero_r, X, y, print_full_cv_results=False)\n",
    "cv_evaluate(zero_r, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510c19d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1R\n",
    "one_r = DecisionTreeClassifier(max_depth=1)\n",
    "cross_val(one_r, X_oe, y, print_full_cv_results=False)\n",
    "cv_evaluate(one_r, X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
